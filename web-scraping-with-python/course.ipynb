{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# full path to body\n",
    "xpath = '/html/body'\n",
    "\n",
    "# takes to any div in doc\n",
    "xpath = '//div'\n",
    "\n",
    "# takes to any span which class equal 'span-class'\n",
    "xpath = \"//span[@class='span-class']\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "# * is the wildcard, takes to any and all childen \n",
    "xpath = '/html/body/*'\n",
    "\n",
    "# /* select all childen, or elements one generation below\n",
    "# //* selects all elements from all future generations of body\n",
    "\n",
    "xpath = '//div/div/*'\n",
    "\n",
    "# accesses every p that class equals 'class-1'\n",
    "xpath = '//p[@class=\"class-1\"]'\n",
    "\n",
    "# access every element that id equals 'uid'\n",
    "xpath = '//*[@id=\"uid\"]'\n",
    "\n",
    "# filter every div that id equals 'uid' and access second paragraph\n",
    "xpath = '//div[@id=\"uid\"]/p[2]'\n",
    "\n",
    "xpath = '/*[contains(@class, \"class-1\")]'\n",
    "\n",
    "xpath = '/html/body/div/p[2]/@class'\n",
    "\n",
    "# Scrapy Part\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "    <body>\n",
    "        <div class=\"hello datacamp\">\n",
    "            <p>Hello World</p>\n",
    "        </div>\n",
    "        <p>Enjoy Datacamp!</p>\n",
    "        <div>Div 1: <p>paragraph 1</p></div>\n",
    "        <div>Div 2: <p>paragraph 2</p> <p>paragraph 3</p> </div>\n",
    "        <div>Div 3: <p>paragraph 4</p> <p>paragraph 5</p> <p>paragraph 6</p></div>\n",
    "        <div>Div 4: <p>paragraph 7</p></div>\n",
    "        <div>Div 5: <p>paragraph 8</p></div>\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Create a Selector selecting html as the HTML document\n",
    "sel = Selector(text=html) \n",
    "\n",
    "# Create a SelectorList of all div elements in the HTML document\n",
    "divs = sel.xpath('//div')\n",
    "\n",
    "print('\\n####divs####\\n')\n",
    "print(divs)\n",
    "print('\\n####divs.extract()####\\n')\n",
    "print(divs.extract())\n",
    "print('\\n####divs.extract_first()####\\n')\n",
    "print(divs.extract_first())\n",
    "\n",
    "# concatenate xpath commands\n",
    "sel.xpath( '//div' ).xpath( \"./span/p[3]\")\n",
    "\n",
    "# HTML text to Selector\n",
    "\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Web_scraping'\n",
    "html = requests.get(url).content\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# print number of elements in page\n",
    "print( \"You have found: \", len( sel.xpath('//*') ) )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "####divs####\n",
      "\n",
      "[<Selector xpath='//div' data='<div class=\"hello datacamp\">\\n        ...'>, <Selector xpath='//div' data='<div>Div 1: <p>paragraph 1</p></div>'>, <Selector xpath='//div' data='<div>Div 2: <p>paragraph 2</p> <p>par...'>, <Selector xpath='//div' data='<div>Div 3: <p>paragraph 4</p> <p>par...'>, <Selector xpath='//div' data='<div>Div 4: <p>paragraph 7</p></div>'>, <Selector xpath='//div' data='<div>Div 5: <p>paragraph 8</p></div>'>]\n",
      "\n",
      "####divs.extract()####\n",
      "\n",
      "['<div class=\"hello datacamp\">\\n            <p>Hello World</p>\\n        </div>', '<div>Div 1: <p>paragraph 1</p></div>', '<div>Div 2: <p>paragraph 2</p> <p>paragraph 3</p> </div>', '<div>Div 3: <p>paragraph 4</p> <p>paragraph 5</p> <p>paragraph 6</p></div>', '<div>Div 4: <p>paragraph 7</p></div>', '<div>Div 5: <p>paragraph 8</p></div>']\n",
      "\n",
      "####divs.extract_first()####\n",
      "\n",
      "<div class=\"hello datacamp\">\n",
      "            <p>Hello World</p>\n",
      "        </div>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CSS Locators\n",
    "\n",
    "- replace / by > (except first character)\n",
    "```\n",
    "- XPath: /hmtl/body/div\n",
    "- CSS Locator: html > body > div\n",
    "```\n",
    "\n",
    "- replace // by a black space (except first character)\n",
    "```\n",
    "- XPath: //div/span//p\n",
    "- CSS Locator: div > span p\n",
    "```\n",
    "\n",
    "- replace [N] by :nth-of-type(N)\n",
    "```\n",
    "- XPath: //div/p[2]\n",
    "- CSS Locator: div > p:nth-of-type(2)\n",
    "```\n",
    "\n",
    "- find an element by class, use a period .\n",
    "```\n",
    "- p.class-1\n",
    "```\n",
    "\n",
    "- find an element by id, use a pound sign #\n",
    "```\n",
    "- div#uid\n",
    "```\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the XPath string equivalent to the CSS Locator \n",
    "```\n",
    "xpath = '//div[@id=\"uid\"]/span//h4'\n",
    "```\n",
    "# Create the CSS Locator string equivalent to the XPath\n",
    "```\n",
    "css_locator = 'div#uid > span h4'\n",
    "```\n",
    "\n",
    "```\n",
    "css_locator = '#uid > *'\n",
    "```"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}